{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-df754c4761d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'twitter_samples'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'averaged_perceptron_tagger'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stopwords'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "nltk.download('twitter_samples')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of adjectives =  6094\n",
      "Total number of nouns =  13180\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "from nltk.tag import pos_tag_sents\n",
    "\n",
    "tweets = twitter_samples.strings('positive_tweets.json')\n",
    "tweets_tokens = twitter_samples.tokenized('positive_tweets.json')\n",
    "tweets_tagged = pos_tag_sents(tweets_tokens) #pos_tag_sents = part of speech tagger for multiple sentences\n",
    "\n",
    "JJ_count = 0\n",
    "NN_count = 0\n",
    "\n",
    "for tweet in tweets_tagged:\n",
    "    for pair in tweet:\n",
    "        tag = pair[1]\n",
    "        if tag == 'JJ':\n",
    "            JJ_count += 1\n",
    "        elif tag == 'NN':\n",
    "            NN_count += 1\n",
    "            \n",
    "print('Total number of adjectives = ', JJ_count)\n",
    "print('Total number of nouns = ', NN_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#FollowFriday',\n",
       " '@France_Inte',\n",
       " '@PKuchly57',\n",
       " '@Milipol_Paris',\n",
       " 'for',\n",
       " 'being',\n",
       " 'top',\n",
       " 'engaged',\n",
       " 'members',\n",
       " 'in',\n",
       " 'my',\n",
       " 'community',\n",
       " 'this',\n",
       " 'week',\n",
       " ':)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#FollowFriday', 'JJ'),\n",
       " ('@France_Inte', 'NNP'),\n",
       " ('@PKuchly57', 'NNP'),\n",
       " ('@Milipol_Paris', 'NNP'),\n",
       " ('for', 'IN'),\n",
       " ('being', 'VBG'),\n",
       " ('top', 'JJ'),\n",
       " ('engaged', 'VBN'),\n",
       " ('members', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('community', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('week', 'NN'),\n",
       " (':)', 'NN')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_tagged[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>TweetTokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
       "      <td>[#followfriday, for, being, top, engaged, memb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
       "      <td>[hey, james, !, how, odd, :/, please, call, ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
       "      <td>[we, had, a, listen, last, night, :), as, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@97sides CONGRATS :)</td>\n",
       "      <td>[@97sides, congrats, :)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
       "      <td>[yeaaaah, yippppy, !, !, !, my, accnt, verifie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  #FollowFriday @France_Inte @PKuchly57 @Milipol...   \n",
       "1  @Lamb2ja Hey James! How odd :/ Please call our...   \n",
       "2  @DespiteOfficial we had a listen last night :)...   \n",
       "3                               @97sides CONGRATS :)   \n",
       "4  yeaaaah yippppy!!!  my accnt verified rqst has...   \n",
       "\n",
       "                                      TweetTokenized  \n",
       "0  [#followfriday, for, being, top, engaged, memb...  \n",
       "1  [hey, james, !, how, odd, :/, please, call, ou...  \n",
       "2  [we, had, a, listen, last, night, :), as, you,...  \n",
       "3                           [@97sides, congrats, :)]  \n",
       "4  [yeaaaah, yippppy, !, !, !, my, accnt, verifie...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = ['Tweet','TweetTokenized']\n",
    "tweets_df = pd.DataFrame(columns = columns)\n",
    "\n",
    "tweets_df['Tweet'] = tweets\n",
    "\n",
    "#import the tweet tokenizer, strip out handles, reduce to lower case, and trim\n",
    "tknzr = nltk.tokenize.TweetTokenizer(strip_handles = True,preserve_case = False, reduce_len = False)\n",
    "\n",
    "for i in tweets_df.index:\n",
    "    tweets_df.loc[i,'TweetTokenized'] = tknzr.tokenize(tweets_df.loc[i,'Tweet'])\n",
    "    \n",
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>TweetTokenized</th>\n",
       "      <th>TokensNoStop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
       "      <td>[#followfriday, for, being, top, engaged, memb...</td>\n",
       "      <td>[#followfriday, top, engaged, members, communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
       "      <td>[hey, james, !, how, odd, :/, please, call, ou...</td>\n",
       "      <td>[hey, james, !, odd, :/, please, call, contact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
       "      <td>[we, had, a, listen, last, night, :), as, you,...</td>\n",
       "      <td>[listen, last, night, :), bleed, amazing, trac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@97sides CONGRATS :)</td>\n",
       "      <td>[@97sides, congrats, :)]</td>\n",
       "      <td>[@97sides, congrats, :)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
       "      <td>[yeaaaah, yippppy, !, !, !, my, accnt, verifie...</td>\n",
       "      <td>[yeaaaah, yippppy, !, !, !, accnt, verified, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  #FollowFriday @France_Inte @PKuchly57 @Milipol...   \n",
       "1  @Lamb2ja Hey James! How odd :/ Please call our...   \n",
       "2  @DespiteOfficial we had a listen last night :)...   \n",
       "3                               @97sides CONGRATS :)   \n",
       "4  yeaaaah yippppy!!!  my accnt verified rqst has...   \n",
       "\n",
       "                                      TweetTokenized  \\\n",
       "0  [#followfriday, for, being, top, engaged, memb...   \n",
       "1  [hey, james, !, how, odd, :/, please, call, ou...   \n",
       "2  [we, had, a, listen, last, night, :), as, you,...   \n",
       "3                           [@97sides, congrats, :)]   \n",
       "4  [yeaaaah, yippppy, !, !, !, my, accnt, verifie...   \n",
       "\n",
       "                                        TokensNoStop  \n",
       "0  [#followfriday, top, engaged, members, communi...  \n",
       "1  [hey, james, !, odd, :/, please, call, contact...  \n",
       "2  [listen, last, night, :), bleed, amazing, trac...  \n",
       "3                           [@97sides, congrats, :)]  \n",
       "4  [yeaaaah, yippppy, !, !, !, accnt, verified, r...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['TokensNoStop'] = None\n",
    "\n",
    "for i in tweets_df.index:\n",
    "    text = tweets_df['TweetTokenized'].iloc[i]\n",
    "    text = [word for word in text if word not in stop]\n",
    "    tweets_df['TokensNoStop'].iloc[i] = text\n",
    "    \n",
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#need to remove punctuation, emoticons etc\n",
    "#then turn it into a table with one word per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>TweetTokenized</th>\n",
       "      <th>TokensNoStop</th>\n",
       "      <th>TokensNoStopNoPunc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
       "      <td>[#followfriday, for, being, top, engaged, memb...</td>\n",
       "      <td>[#followfriday, top, engaged, members, communi...</td>\n",
       "      <td>[#followfriday, top, engaged, members, communi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
       "      <td>[hey, james, !, how, odd, :/, please, call, ou...</td>\n",
       "      <td>[hey, james, !, odd, :/, please, call, contact...</td>\n",
       "      <td>[hey, james, odd, please, call, contact, centr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
       "      <td>[we, had, a, listen, last, night, :), as, you,...</td>\n",
       "      <td>[listen, last, night, :), bleed, amazing, trac...</td>\n",
       "      <td>[listen, last, night, bleed, amazing, track, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@97sides CONGRATS :)</td>\n",
       "      <td>[@97sides, congrats, :)]</td>\n",
       "      <td>[@97sides, congrats, :)]</td>\n",
       "      <td>[@97sides, congrats]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
       "      <td>[yeaaaah, yippppy, !, !, !, my, accnt, verifie...</td>\n",
       "      <td>[yeaaaah, yippppy, !, !, !, accnt, verified, r...</td>\n",
       "      <td>[yeaaaah, yippppy, accnt, verified, rqst, succ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  #FollowFriday @France_Inte @PKuchly57 @Milipol...   \n",
       "1  @Lamb2ja Hey James! How odd :/ Please call our...   \n",
       "2  @DespiteOfficial we had a listen last night :)...   \n",
       "3                               @97sides CONGRATS :)   \n",
       "4  yeaaaah yippppy!!!  my accnt verified rqst has...   \n",
       "\n",
       "                                      TweetTokenized  \\\n",
       "0  [#followfriday, for, being, top, engaged, memb...   \n",
       "1  [hey, james, !, how, odd, :/, please, call, ou...   \n",
       "2  [we, had, a, listen, last, night, :), as, you,...   \n",
       "3                           [@97sides, congrats, :)]   \n",
       "4  [yeaaaah, yippppy, !, !, !, my, accnt, verifie...   \n",
       "\n",
       "                                        TokensNoStop  \\\n",
       "0  [#followfriday, top, engaged, members, communi...   \n",
       "1  [hey, james, !, odd, :/, please, call, contact...   \n",
       "2  [listen, last, night, :), bleed, amazing, trac...   \n",
       "3                           [@97sides, congrats, :)]   \n",
       "4  [yeaaaah, yippppy, !, !, !, accnt, verified, r...   \n",
       "\n",
       "                                  TokensNoStopNoPunc  \n",
       "0  [#followfriday, top, engaged, members, communi...  \n",
       "1  [hey, james, odd, please, call, contact, centr...  \n",
       "2  [listen, last, night, bleed, amazing, track, ....  \n",
       "3                               [@97sides, congrats]  \n",
       "4  [yeaaaah, yippppy, accnt, verified, rqst, succ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation = ['!','?',':)',':/',':(',':D','<3']\n",
    "\n",
    "tweets_df['TokensNoStopNoPunc'] = None\n",
    "\n",
    "for i in tweets_df.index:\n",
    "    text = tweets_df['TokensNoStop'].iloc[i]\n",
    "    text = [word for word in text if word not in punctuation]\n",
    "    tweets_df['TokensNoStopNoPunc'].iloc[i] = text\n",
    "    \n",
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>TweetTokenized</th>\n",
       "      <th>TokensNoStop</th>\n",
       "      <th>TokensNoStopNoPunc</th>\n",
       "      <th>TokensNoStopNoPunc_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#FollowFriday @France_Inte @PKuchly57 @Milipol...</td>\n",
       "      <td>[#followfriday, for, being, top, engaged, memb...</td>\n",
       "      <td>[#followfriday, top, engaged, members, communi...</td>\n",
       "      <td>[#followfriday, top, engaged, members, communi...</td>\n",
       "      <td>[#followfriday, top, engag, member, commun, week]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Lamb2ja Hey James! How odd :/ Please call our...</td>\n",
       "      <td>[hey, james, !, how, odd, :/, please, call, ou...</td>\n",
       "      <td>[hey, james, !, odd, :/, please, call, contact...</td>\n",
       "      <td>[hey, james, odd, please, call, contact, centr...</td>\n",
       "      <td>[hey, jame, odd, pleas, call, contact, centr, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@DespiteOfficial we had a listen last night :)...</td>\n",
       "      <td>[we, had, a, listen, last, night, :), as, you,...</td>\n",
       "      <td>[listen, last, night, :), bleed, amazing, trac...</td>\n",
       "      <td>[listen, last, night, bleed, amazing, track, ....</td>\n",
       "      <td>[listen, last, night, bleed, amaz, track, ., s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@97sides CONGRATS :)</td>\n",
       "      <td>[@97sides, congrats, :)]</td>\n",
       "      <td>[@97sides, congrats, :)]</td>\n",
       "      <td>[@97sides, congrats]</td>\n",
       "      <td>[@97side, congrat]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yeaaaah yippppy!!!  my accnt verified rqst has...</td>\n",
       "      <td>[yeaaaah, yippppy, !, !, !, my, accnt, verifie...</td>\n",
       "      <td>[yeaaaah, yippppy, !, !, !, accnt, verified, r...</td>\n",
       "      <td>[yeaaaah, yippppy, accnt, verified, rqst, succ...</td>\n",
       "      <td>[yeaaaah, yippppi, accnt, verifi, rqst, succee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  \\\n",
       "0  #FollowFriday @France_Inte @PKuchly57 @Milipol...   \n",
       "1  @Lamb2ja Hey James! How odd :/ Please call our...   \n",
       "2  @DespiteOfficial we had a listen last night :)...   \n",
       "3                               @97sides CONGRATS :)   \n",
       "4  yeaaaah yippppy!!!  my accnt verified rqst has...   \n",
       "\n",
       "                                      TweetTokenized  \\\n",
       "0  [#followfriday, for, being, top, engaged, memb...   \n",
       "1  [hey, james, !, how, odd, :/, please, call, ou...   \n",
       "2  [we, had, a, listen, last, night, :), as, you,...   \n",
       "3                           [@97sides, congrats, :)]   \n",
       "4  [yeaaaah, yippppy, !, !, !, my, accnt, verifie...   \n",
       "\n",
       "                                        TokensNoStop  \\\n",
       "0  [#followfriday, top, engaged, members, communi...   \n",
       "1  [hey, james, !, odd, :/, please, call, contact...   \n",
       "2  [listen, last, night, :), bleed, amazing, trac...   \n",
       "3                           [@97sides, congrats, :)]   \n",
       "4  [yeaaaah, yippppy, !, !, !, accnt, verified, r...   \n",
       "\n",
       "                                  TokensNoStopNoPunc  \\\n",
       "0  [#followfriday, top, engaged, members, communi...   \n",
       "1  [hey, james, odd, please, call, contact, centr...   \n",
       "2  [listen, last, night, bleed, amazing, track, ....   \n",
       "3                               [@97sides, congrats]   \n",
       "4  [yeaaaah, yippppy, accnt, verified, rqst, succ...   \n",
       "\n",
       "                          TokensNoStopNoPunc_stemmed  \n",
       "0  [#followfriday, top, engag, member, commun, week]  \n",
       "1  [hey, jame, odd, pleas, call, contact, centr, ...  \n",
       "2  [listen, last, night, bleed, amaz, track, ., s...  \n",
       "3                                 [@97side, congrat]  \n",
       "4  [yeaaaah, yippppi, accnt, verifi, rqst, succee...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "tweets_df['TokensNoStopNoPunc_stemmed'] = None\n",
    "\n",
    "for i in tweets_df.index:\n",
    "    t = tweets_df['TokensNoStopNoPunc'].iloc[i]\n",
    "    \n",
    "    l = []\n",
    "\n",
    "    for word in t:\n",
    "        a = stemmer.stem(word)\n",
    "        l.append(a)\n",
    "        \n",
    "    tweets_df['TokensNoStopNoPunc_stemmed'].iloc[i] = l\n",
    "    \n",
    "tweets_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_cols = ['TweetID','Bigram']\n",
    "bigram_df = pd.DataFrame(columns = bigram_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in tweets_df.index.values:\n",
    "    test = list(nltk.bigrams(tweets_df['TokensNoStopNoPunc_stemmed'].iloc[tweet]))\n",
    "    for t in test:\n",
    "        tweet_dict ={'TweetID' : [tweet], 'Bigram' : [t]}\n",
    "        df_temp = pd.DataFrame(data = tweet_dict)\n",
    "        bigram_df = bigram_df.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_df = bigram_df.reset_index(drop = True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_df['Bigram1'],bigram_df['Bigram2'] = zip(*bigram_df['Bigram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 #followfriday top\n",
       "1                         top engag\n",
       "2                      engag member\n",
       "3                     member commun\n",
       "4                       commun week\n",
       "5                          hey jame\n",
       "6                          jame odd\n",
       "7                         odd pleas\n",
       "8                        pleas call\n",
       "9                      call contact\n",
       "10                    contact centr\n",
       "11                centr 02392441234\n",
       "12                  02392441234 abl\n",
       "13                       abl assist\n",
       "14                      assist mani\n",
       "15                       mani thank\n",
       "16                      listen last\n",
       "17                       last night\n",
       "18                      night bleed\n",
       "19                       bleed amaz\n",
       "20                       amaz track\n",
       "21                          track .\n",
       "22                       . scotland\n",
       "23                  @97side congrat\n",
       "24                  yeaaaah yippppi\n",
       "25                    yippppi accnt\n",
       "26                     accnt verifi\n",
       "27                      verifi rqst\n",
       "28                     rqst succeed\n",
       "29                      succeed got\n",
       "                    ...            \n",
       "30739                   that' great\n",
       "30740                    great hear\n",
       "30741                      hear due\n",
       "30742                      due time\n",
       "30743                        time &\n",
       "30744                      & remind\n",
       "30745                   remind inde\n",
       "30746                     inde plan\n",
       "30747                        plan ,\n",
       "30748                       , avail\n",
       "30749                 avail distant\n",
       "30750                 distant futur\n",
       "30751               thank shout-out\n",
       "30752               shout-out great\n",
       "30753                  great aboard\n",
       "30754                      hey long\n",
       "30755                     long time\n",
       "30756                     time talk\n",
       "30757                      talk ...\n",
       "30758                    matt would\n",
       "30759                     would say\n",
       "30760                         say .\n",
       "30761                      . welcom\n",
       "30762              welcom adulthood\n",
       "30763                 adulthood ...\n",
       "30764    ... http://t.co/zHQy0iyaCP\n",
       "30765                     could say\n",
       "30766                       say egg\n",
       "30767                      egg face\n",
       "30768                      face :-)\n",
       "Length: 30769, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_df['Bigram1'] + ' ' + bigram_df['Bigram2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
